Wed Feb  7 22:42:06 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A800-SXM4-80GB          Off | 00000000:1F:00.0 Off |                    0 |
| N/A   21C    P0              58W / 400W |      2MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA A800-SXM4-80GB          Off | 00000000:25:00.0 Off |                    0 |
| N/A   25C    P0              57W / 400W |      2MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA A800-SXM4-80GB          Off | 00000000:50:00.0 Off |                    0 |
| N/A   25C    P0              58W / 400W |      2MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA A800-SXM4-80GB          Off | 00000000:55:00.0 Off |                    0 |
| N/A   22C    P0              57W / 400W |      2MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA A800-SXM4-80GB          Off | 00000000:8D:00.0 Off |                    0 |
| N/A   23C    P0              58W / 400W |      2MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA A800-SXM4-80GB          Off | 00000000:92:00.0 Off |                    0 |
| N/A   25C    P0              59W / 400W |      2MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA A800-SXM4-80GB          Off | 00000000:C9:00.0 Off |                    0 |
| N/A   27C    P0              59W / 400W |      2MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA A800-SXM4-80GB          Off | 00000000:CF:00.0 Off |                    0 |
| N/A   23C    P0              58W / 400W |      2MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
++ /usr/bin/tclsh /usr/local/Modules/libexec/modulecmd.tcl bash load anaconda3
+ eval 'PATH=/hpc2ssd/softwares/anaconda3/bin:/hpc2hdd/home/wenshuozhang/.local/bin:/hpc2hdd/home/wenshuozhang/bin:/opt/slurm/bin:/usr/local/Modules/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/go/bin:/root/go/bin; export PATH;
_LMFILES_=/usr/local/Modules/modulefiles/slurm:/usr/local/Modules/modulefiles/anaconda3; export _LMFILES_;
LOADEDMODULES=slurm:anaconda3; export LOADEDMODULES;
test 0;'
++ PATH=/hpc2ssd/softwares/anaconda3/bin:/hpc2hdd/home/wenshuozhang/.local/bin:/hpc2hdd/home/wenshuozhang/bin:/opt/slurm/bin:/usr/local/Modules/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/go/bin:/root/go/bin
++ export PATH
++ _LMFILES_=/usr/local/Modules/modulefiles/slurm:/usr/local/Modules/modulefiles/anaconda3
++ export _LMFILES_
++ LOADEDMODULES=slurm:anaconda3
++ export LOADEDMODULES
++ test 0
+ _mlstatus=0
+ return 0
++ /usr/bin/tclsh /usr/local/Modules/libexec/modulecmd.tcl bash load cuda/12.2
+ eval 'LD_LIBRARY_PATH=/hpc2ssd/softwares/cuda/cuda-12.2/lib64:/opt/slurm/lib; export LD_LIBRARY_PATH;
__MODULES_LMALTNAME=cuda/12.2\&as\|cuda/default\&as\|cuda/latest; export __MODULES_LMALTNAME;
PATH=/hpc2ssd/softwares/cuda/cuda-12.2/bin:/hpc2ssd/softwares/anaconda3/bin:/hpc2hdd/home/wenshuozhang/.local/bin:/hpc2hdd/home/wenshuozhang/bin:/opt/slurm/bin:/usr/local/Modules/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/go/bin:/root/go/bin; export PATH;
_LMFILES_=/usr/local/Modules/modulefiles/slurm:/usr/local/Modules/modulefiles/anaconda3:/usr/local/Modules/modulefiles/cuda/12.2; export _LMFILES_;
LOADEDMODULES=slurm:anaconda3:cuda/12.2; export LOADEDMODULES;
test 0;'
++ LD_LIBRARY_PATH=/hpc2ssd/softwares/cuda/cuda-12.2/lib64:/opt/slurm/lib
++ export LD_LIBRARY_PATH
++ __MODULES_LMALTNAME='cuda/12.2&as|cuda/default&as|cuda/latest'
++ export __MODULES_LMALTNAME
++ PATH=/hpc2ssd/softwares/cuda/cuda-12.2/bin:/hpc2ssd/softwares/anaconda3/bin:/hpc2hdd/home/wenshuozhang/.local/bin:/hpc2hdd/home/wenshuozhang/bin:/opt/slurm/bin:/usr/local/Modules/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/go/bin:/root/go/bin
++ export PATH
++ _LMFILES_=/usr/local/Modules/modulefiles/slurm:/usr/local/Modules/modulefiles/anaconda3:/usr/local/Modules/modulefiles/cuda/12.2
++ export _LMFILES_
++ LOADEDMODULES=slurm:anaconda3:cuda/12.2
++ export LOADEDMODULES
++ test 0
+ _mlstatus=0
+ return 0
++ /usr/bin/tclsh /usr/local/Modules/libexec/modulecmd.tcl bash load slurm
+ eval ''
+ _mlstatus=0
+ return 0
We are going to run the main file
We finish loding
EPOCH,BATCH_SIZE,VAL_BATCH_SIZE,NODE_RANK ,WORLD_SIZE,lr 4 12 6 0 8 5e-05
The total world_size is : 8 and we started to train!
We finish loding
EPOCH,BATCH_SIZE,VAL_BATCH_SIZE,NODE_RANK ,WORLD_SIZE,lr 4 12 6 0 8 5e-05
We finished the setting up process!
The device we use are shown here:  cuda:5
We have loaded Vit-B/32: 
Length of val_dataloader:  1697
train_dataloader is prepared and its length is:  1017712 1007534 10178



 We are in epoch:  0  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  1  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  2  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  3  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
We finished the cleaning up process!
We finish loding
EPOCH,BATCH_SIZE,VAL_BATCH_SIZE,NODE_RANK ,WORLD_SIZE,lr 4 12 6 0 8 5e-05
We finished the setting up process!
The device we use are shown here:  cuda:7
We have loaded Vit-B/32: 
Length of val_dataloader:  1697
train_dataloader is prepared and its length is:  1017712 1007534 10178



 We are in epoch:  0  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  1  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  2  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  3  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
We finished the cleaning up process!
We finish loding
EPOCH,BATCH_SIZE,VAL_BATCH_SIZE,NODE_RANK ,WORLD_SIZE,lr 4 12 6 0 8 5e-05
We finished the setting up process!
The device we use are shown here:  cuda:2
We have loaded Vit-B/32: 
Length of val_dataloader:  1697
train_dataloader is prepared and its length is:  1017712 1007534 10178



 We are in epoch:  0  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  1  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  2  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  3  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
We finished the cleaning up process!
We finish loding
EPOCH,BATCH_SIZE,VAL_BATCH_SIZE,NODE_RANK ,WORLD_SIZE,lr 4 12 6 0 8 5e-05
We finished the setting up process!
The device we use are shown here:  cuda:3
We have loaded Vit-B/32: 
Length of val_dataloader:  1697
train_dataloader is prepared and its length is:  1017712 1007534 10178



 We are in epoch:  0  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  1  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  2  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  3  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
We finished the cleaning up process!
We finish loding
EPOCH,BATCH_SIZE,VAL_BATCH_SIZE,NODE_RANK ,WORLD_SIZE,lr 4 12 6 0 8 5e-05
We finished the setting up process!
The device we use are shown here:  cuda:6
We have loaded Vit-B/32: 
Length of val_dataloader:  1697
train_dataloader is prepared and its length is:  1017712 1007534 10178



 We are in epoch:  0  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  1  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  2  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  3  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
We finished the cleaning up process!
We finish loding
EPOCH,BATCH_SIZE,VAL_BATCH_SIZE,NODE_RANK ,WORLD_SIZE,lr 4 12 6 0 8 5e-05
We finished the setting up process!
The device we use are shown here:  cuda:4
We have loaded Vit-B/32: 
Length of val_dataloader:  1697
train_dataloader is prepared and its length is:  1017712 1007534 10178



 We are in epoch:  0  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  1  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  2  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  3  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
We finished the cleaning up process!
We finish loding
EPOCH,BATCH_SIZE,VAL_BATCH_SIZE,NODE_RANK ,WORLD_SIZE,lr 4 12 6 0 8 5e-05
We finished the setting up process!
The device we use are shown here:  cuda:1
We have loaded Vit-B/32: 
Length of val_dataloader:  1697
train_dataloader is prepared and its length is:  1017712 1007534 10178



 We are in epoch:  0  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  1  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  2  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])



 We are in epoch:  3  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
We finished the cleaning up process!
We finish loding
EPOCH,BATCH_SIZE,VAL_BATCH_SIZE,NODE_RANK ,WORLD_SIZE,lr 4 12 6 0 8 5e-05
We finished the setting up process!
The device we use are shown here:  cuda:0
We have loaded Vit-B/32: 
Length of val_dataloader:  1697
train_dataloader is prepared and its length is:  1017712 1007534 10178



 We are in epoch:  0  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
top_k_accuracies_image, top_k_accuracies_text:  {1: 0.06666667014360428, 5: 0.20000001788139343} {1: 0.10000000894069672, 5: 0.1666666716337204}
loss 2.927734375
loss 2.94140625
loss 4.1015625
loss 5.375
loss 2.771484375
loss 2.55078125
loss 2.76953125



 We are in epoch:  1  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
top_k_accuracies_image, top_k_accuracies_text:  {1: 0.0, 5: 0.1666666716337204} {1: 0.0, 5: 0.1666666716337204}
loss 2.65234375
loss 2.61328125
loss 2.52734375
loss 2.53515625
loss 2.513671875
loss 2.51953125
loss 2.51171875



 We are in epoch:  2  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
top_k_accuracies_image, top_k_accuracies_text:  {1: 0.06666667014360428, 5: 0.20000001788139343} {1: 0.06666667014360428, 5: 0.1666666716337204}
loss 2.4921875
loss 2.49609375
loss 2.49609375
loss 2.48828125
loss 2.494140625
loss 2.48828125
loss 2.501953125



 We are in epoch:  3  out of total epoch:  4
We Finished the preprocess for images and texts
Image and Text shape:  torch.Size([12, 3, 224, 224]) torch.Size([12, 77])
top_k_accuracies_image, top_k_accuracies_text:  {1: 0.03333333507180214, 5: 0.1666666716337204} {1: 0.0, 5: 0.1666666716337204}
loss 2.49609375
loss 2.494140625
loss 2.48828125
loss 2.490234375
loss 2.48828125
loss 2.48828125
loss 2.48828125
wandb has been closed!
We finished the cleaning up process!
Finished! Total time: 222
